{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# OpenAI Agent Query Planning\n",
    "In this demo, we explore adding a QueryPlanTool to an OpenAIAgent. This effectively enables the agent to do advanced query planning, all through a single tool!\n",
    "\n",
    "The QueryPlanTool is designed to work well with the OpenAI Function API. The tool takes in a set of other tools as input. The tool function signature contains of a QueryPlan Pydantic object, which can in turn contain a DAG of QueryNode objects defining a compute graph. The agent is responsible for defining this graph through the function signature when calling the tool. The tool itself executes the DAG over any corresponding tools.\n",
    "\n",
    "In this setting we use a familiar example: Uber 10Q filings in March, June, and September of 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This is ONLY necessary in jupyter notebook.\n",
    "# Details: Jupyter runs an event-loop behind the scenes.\n",
    "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
    "#          This is normally not allowed, we use nest_asyncio to allow it for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LlamaDebugHandler to print the trace of the sub questions\n",
    "# captured by the SUB_QUESTION callback event type\n",
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "\n",
    "Settings.callback_manager = callback_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/10q/', exist_ok=True)\n",
    "!curl \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_march_2022.pdf\" -o \"./data/10q/uber_10q_march_2022.pdf\"\n",
    "!curl \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_june_2022.pdf\" -o \"./data/10q/uber_10q_june_2022.pdf\"\n",
    "!curl \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_sept_2022.pdf\" -o \"./data/10q/uber_10q_sept_2022.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_2022 = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10q/uber_10q_march_2022.pdf\"]\n",
    ").load_data()\n",
    "june_2022 = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10q/uber_10q_june_2022.pdf\"]\n",
    ").load_data()\n",
    "sept_2022 = SimpleDirectoryReader(\n",
    "    input_files=[\"./data/10q/uber_10q_sept_2022.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build indices\n",
    "We build a vector index / query engine over each of the documents (March, June, September)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_index = VectorStoreIndex.from_documents(march_2022)\n",
    "june_index = VectorStoreIndex.from_documents(june_2022)\n",
    "sept_index = VectorStoreIndex.from_documents(sept_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_index.storage_context.persist(persist_dir=\"./march_index\")\n",
    "june_index.storage_context.persist(persist_dir=\"./june_2022\")\n",
    "sept_index.storage_context.persist(persist_dir=\"./sept_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "march_engine = march_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "june_engine = june_index.as_query_engine(similarity_top_k=3, llm=llm)\n",
    "sept_engine = sept_index.as_query_engine(similarity_top_k=3, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Function Agent with a Query Plan Tool\n",
    "Use OpenAIAgent, built on top of the OpenAI tool use interface.\n",
    "\n",
    "Feed it our QueryPlanTool, which is a Tool that takes in other tools. And the agent to generate a query plan DAG over these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "\n",
    "query_tool_sept = QueryEngineTool.from_defaults(\n",
    "    query_engine=sept_engine,\n",
    "    name=\"sept_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending\"\n",
    "        f\" September 2022\"\n",
    "    ),\n",
    ")\n",
    "query_tool_june = QueryEngineTool.from_defaults(\n",
    "    query_engine=june_engine,\n",
    "    name=\"june_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending\"\n",
    "        f\" June 2022\"\n",
    "    ),\n",
    ")\n",
    "query_tool_march = QueryEngineTool.from_defaults(\n",
    "    query_engine=march_engine,\n",
    "    name=\"march_2022\",\n",
    "    description=(\n",
    "        f\"Provides information about Uber quarterly financials ending\"\n",
    "        f\" March 2022\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define query plan tool\n",
    "from llama_index.core.tools import QueryPlanTool\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "query_plan_tool = QueryPlanTool.from_defaults(\n",
    "    query_engine_tools=[query_tool_sept, query_tool_june, query_tool_march],\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_plan_tool.metadata.to_openai_tool()  # to_openai_function() deprecated\n",
    "\n",
    "#query_plan_tool.metadata.to_openai_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_plan_tool.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [query_plan_tool],\n",
    "    max_function_calls=10,\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4o-mini\"),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"What were the risk factors in march 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"What were the risk factors in sept 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools.query_plan import QueryPlan, QueryNode\n",
    "\n",
    "query_plan = QueryPlan(\n",
    "    nodes=[\n",
    "        QueryNode(\n",
    "            id=1,\n",
    "            query_str=\"risk factors\",\n",
    "            tool_name=\"sept_2022\",\n",
    "            dependencies=[],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryPlan.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Analyze Uber revenue growth in March, June, and September 2022\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Analyze changes in risk factors in march, june, and september for Uber\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\"Analyze both Uber revenue growth and risk factors over march, june, and september\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"First look at Uber's revenue growth and risk factors in March, \"\n",
    "    + \"then revenue growth and risk factors in September, and then compare and\"\n",
    "    \" contrast the two documents?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
